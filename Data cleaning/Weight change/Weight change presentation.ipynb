{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First read in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = \"D:/Laptop Data/Louis Box 2664/Documents/gym data project/weight change/01-07-19 weight bulk.csv\"\n",
    "wc = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets take look at what we've got"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Weight (lbs)</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01/07/2019</td>\n",
       "      <td>180.06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>02/07/2019</td>\n",
       "      <td>181</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>03/07/2019</td>\n",
       "      <td>181</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>04/07/2019</td>\n",
       "      <td>180</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>05/07/2019</td>\n",
       "      <td>179.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>06/07/2019</td>\n",
       "      <td>181.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>07/07/2019</td>\n",
       "      <td>181</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>week 1 average</td>\n",
       "      <td>NaN</td>\n",
       "      <td>180.64</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Date Weight (lbs)   Unnamed: 2 Unnamed: 3\n",
       "0       01/07/2019        180.06         NaN        NaN\n",
       "1       02/07/2019           181         NaN        NaN\n",
       "2       03/07/2019           181         NaN        NaN\n",
       "3       04/07/2019           180         NaN        NaN\n",
       "4       05/07/2019         179.6         NaN        NaN\n",
       "5       06/07/2019         181.8         NaN        NaN\n",
       "6       07/07/2019           181         NaN        NaN\n",
       "7              NaN           NaN         NaN        NaN\n",
       "8  week 1 average            NaN      180.64       0.58\n",
       "9              NaN           NaN         NaN        NaN"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wc.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 99 entries, 0 to 98\n",
      "Data columns (total 4 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   Date           80 non-null     object \n",
      " 1   Weight (lbs)   70 non-null     object \n",
      " 2   Unnamed: 2     11 non-null     float64\n",
      " 3   Unnamed: 3     12 non-null     object \n",
      "dtypes: float64(1), object(3)\n",
      "memory usage: 3.2+ KB\n"
     ]
    }
   ],
   "source": [
    "wc.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We've got a few things to work on. There a two columns which we dont need, they seem to be used to perform some calculations on average,difference etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So lets drop the third column onwards. Remember to set inplace=True so that the dataframe is actually changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "wc.drop(columns = wc.columns[2:], inplace =True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are rows that act as visual seperators before and after each week. Lets remove them using Pandas' pd.dropna. Setting how = \"all\" drops rows where every value is Na."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "wc.dropna(how=\"all\",inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looks good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Weight (lbs)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01/07/2019</td>\n",
       "      <td>180.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>02/07/2019</td>\n",
       "      <td>181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>03/07/2019</td>\n",
       "      <td>181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>04/07/2019</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>05/07/2019</td>\n",
       "      <td>179.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>06/07/2019</td>\n",
       "      <td>181.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>07/07/2019</td>\n",
       "      <td>181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>week 1 average</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>08/07/2019</td>\n",
       "      <td>182.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>09/07/2019</td>\n",
       "      <td>182.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Date Weight (lbs) \n",
       "0        01/07/2019        180.06\n",
       "1        02/07/2019           181\n",
       "2        03/07/2019           181\n",
       "3        04/07/2019           180\n",
       "4        05/07/2019         179.6\n",
       "5        06/07/2019         181.8\n",
       "6        07/07/2019           181\n",
       "8   week 1 average            NaN\n",
       "10       08/07/2019         182.6\n",
       "11       09/07/2019         182.7"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wc.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we start the next step, we need to make sure we reset our index, since because we removed numerous rows we no longer have a continuous index. As you can see above we are missing row 7 & 9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "wc.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next we want to get rid of the \"week x average\" rows. Since they come at the end of every 7 days, we can drop every 7th row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "wc.drop(labels = wc.iloc[7::8].index.to_list(), inplace=True) # STARTING FROM INDEX 7 AND UP TO EVERY 8TH ITEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "wc.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After a quick name change for the columns. Lets convert the weight column to numeric values using pd.to_numeric, as this will allow us to perform calculations on them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "wc.columns = [\"Date\",\"Weight\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unable to parse string \"183.8?\" at position 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mpandas\\_libs\\lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.maybe_convert_numeric\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Unable to parse string \"183.8?\"",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-3714542acec7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mwc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Weight\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Weight\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_numeric\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[0;32m   3846\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3847\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3848\u001b[1;33m                 \u001b[0mmapped\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3850\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\numeric.py\u001b[0m in \u001b[0;36mto_numeric\u001b[1;34m(arg, errors, downcast)\u001b[0m\n\u001b[0;32m    148\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m             values = lib.maybe_convert_numeric(\n\u001b[1;32m--> 150\u001b[1;33m                 \u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcoerce_numeric\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcoerce_numeric\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m             )\n\u001b[0;32m    152\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mValueError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.maybe_convert_numeric\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Unable to parse string \"183.8?\" at position 0"
     ]
    }
   ],
   "source": [
    "wc[\"Weight\"] = wc[\"Weight\"].apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python has thrown us a ValueError. Looks like not every value contains purely digits. lets have a look at what and how many items are going to cause an issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['183.8?', '184.6!', '188.6?', '189.6??', '191;']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l=[]\n",
    "for n in wc[\"Weight\"]:\n",
    "    try:\n",
    "        pd.to_numeric(n)\n",
    "    except ValueError:\n",
    "        l.append(n)  \n",
    "l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This shouldn't be hard to fix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wc[\"Date\"] = wc[\"Date\"].apply(pd.to_datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_weight(n):\n",
    "    if type(n) == str:\n",
    "        fix = \"\"\n",
    "        for v in n:\n",
    "            if v.isdigit() or v==\".\":\n",
    "                fix += v\n",
    "        return fix\n",
    "    else:\n",
    "        return n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "wc[\"Weight\"] = wc[\"Weight\"].apply(fix_weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### That seemed to work!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Now lets add a new column that indicates whether I was trying to gain, lose, maintain weight etc\n",
    "To do this is simple, we can look at the file name and fill in value based on that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BulkCutFill(file):\n",
    "    if \"bulk\" in file.lower():\n",
    "        wc[\"Goal\"] = \"Bulk\"\n",
    "    elif \"mini\" in file.lower():\n",
    "        wc[\"Goal\"] = \"Mini-cut\"\n",
    "    elif \"cut\" in file.lower():\n",
    "        wc[\"Goal\"] = \"Cut\"\n",
    "    elif \"maintain\" in file.lower():\n",
    "        wc[\"Goal\"] = \"Maintain\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "BulkCutFill(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The date format that we have currently isnt the best. Ideally we would want it in the format dd/mm/yyyy.\n",
    "This function converts the string to datetime based on the format \"%d/%m/%Y\". Then back to a string with the new format \"%Y-%m-%d\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "def convert_date_format(n):\n",
    "    return datetime.datetime.strptime(n, \"%d/%m/%Y\").strftime(\"%Y-%m-%d\") # \"Y\" MEANS YYYY AND \"y\"MEANS YY."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "wc[\"Date\"] = wc[\"Date\"].apply(convert_date_format)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now the dataframe is looking much better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Goal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-07-01</td>\n",
       "      <td>180.06</td>\n",
       "      <td>Bulk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-07-02</td>\n",
       "      <td>181</td>\n",
       "      <td>Bulk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-07-03</td>\n",
       "      <td>181</td>\n",
       "      <td>Bulk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-07-04</td>\n",
       "      <td>180</td>\n",
       "      <td>Bulk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-07-05</td>\n",
       "      <td>179.6</td>\n",
       "      <td>Bulk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2019-07-06</td>\n",
       "      <td>181.8</td>\n",
       "      <td>Bulk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2019-07-07</td>\n",
       "      <td>181</td>\n",
       "      <td>Bulk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2019-07-08</td>\n",
       "      <td>182.6</td>\n",
       "      <td>Bulk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2019-07-09</td>\n",
       "      <td>182.7</td>\n",
       "      <td>Bulk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2019-07-10</td>\n",
       "      <td>182.8</td>\n",
       "      <td>Bulk</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  Weight  Goal\n",
       "0  2019-07-01  180.06  Bulk\n",
       "1  2019-07-02     181  Bulk\n",
       "2  2019-07-03     181  Bulk\n",
       "3  2019-07-04     180  Bulk\n",
       "4  2019-07-05   179.6  Bulk\n",
       "5  2019-07-06   181.8  Bulk\n",
       "6  2019-07-07     181  Bulk\n",
       "7  2019-07-08   182.6  Bulk\n",
       "8  2019-07-09   182.7  Bulk\n",
       "9  2019-07-10   182.8  Bulk"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wc.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The last thing to do is loop through all the files and concatenate them into a single dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now I'll spare you the trouble of watching me attempt to debug the process of looping through the files. But one of the issues that I ran into was that the function os.scadir() from the OS library, would read in the files in a random order. Which is an issue for us as since we are concatenating everything into a single file, the order matters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There isn't an easy way of sorting dates in string format, since most sorting algorithms do so lexicographically and therefore will interpret the date \"10/6/19\" to be before \"2/6/19\" as \"1\" is less than \"2\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def order_dates(folder_path): # TAKES IN THE FOLDER PATH OF THE FILES TO SORT\n",
    "    \n",
    "    split_date = [ n.split(\" \",1)[0] for n in os.listdir(folder_path)] # CREATE A LIST OF THE DATES IN THE FILE NAME\n",
    "                                                                       # BY SPLITTING ONCE ON A SPACE\n",
    "\n",
    "    date_order = [datetime.datetime.strptime(i, \"%d-%m-%y\") for i in split_date] # CONVERT DATE STRINGS TO DATETIME\n",
    "    date_order.sort() # SORT THEM\n",
    "\n",
    "    string_order = [datetime.datetime.strftime(i, \"%d-%m-%y\") for i in date_order] # CONVERT BACK TO STRING\n",
    "\n",
    "    full_string = [str(n) for n in os.listdir(folder_path)] # LIST OF FILE NAMES\n",
    "\n",
    "    file_order = [i for n in string_order for i in full_string if n in i] # REORDER LIST OF FILE NAMES\n",
    "    return file_order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And putting it all together with a few tweaks we get this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "def order_dates(folder_path):\n",
    "    split_date = [ n.split(\" \",1)[0] for n in os.listdir(folder_path)]\n",
    "\n",
    "    date_order = [datetime.datetime.strptime(i, \"%d-%m-%y\") for i in split_date]\n",
    "    date_order.sort()\n",
    "\n",
    "    string_order = [datetime.datetime.strftime(i, \"%d-%m-%y\") for i in date_order]\n",
    "\n",
    "    full_string = [str(n) for n in os.listdir(folder_path)]\n",
    "\n",
    "    file_order = [i for n in string_order for i in full_string if n in i]\n",
    "    return file_order\n",
    "\n",
    "def fix_weight(n):\n",
    "    if type(n) == str:\n",
    "        fix = \"\"\n",
    "        for v in n:\n",
    "            if v.isdigit() or v==\".\":\n",
    "                fix += v\n",
    "        return fix\n",
    "    else:\n",
    "        return n\n",
    "\n",
    "def BulkCutFill(file):\n",
    "    if \"bulk\" in file.lower():\n",
    "        wc[\"Goal\"] = \"Bulk\"\n",
    "    elif \"mini\" in file.lower():\n",
    "        wc[\"Goal\"] = \"Mini-cut\"\n",
    "    elif \"cut\" in file.lower():\n",
    "        wc[\"Goal\"] = \"Cut\"\n",
    "    elif \"maintain\" in file.lower():\n",
    "        wc[\"Goal\"] = \"Maintain\"\n",
    "        \n",
    "def convert_date_format(n):\n",
    "    return datetime.datetime.strptime(n, \"%d/%m/%Y\").strftime(\"%Y-%m-%d\")\n",
    "\n",
    "folder_path = \"D:/Laptop Data/Louis Box 2664/Documents/gym data project/weight change/\"\n",
    "\n",
    "col = [\"Date\",\"Weight\",\"Goal\"]\n",
    "\n",
    "concat_df = pd.DataFrame(columns = col)\n",
    "\n",
    "files = [folder_path + n for n in order_dates(folder_path)]\n",
    "\n",
    "def full_cleaning():\n",
    "    for f in files:\n",
    "\n",
    "        wc = pd.read_csv(f)\n",
    "\n",
    "        wc.drop(columns = wc.columns[2:], inplace =True)\n",
    "        wc.dropna(how=\"all\",inplace=True)\n",
    "        wc.reset_index(drop=True,inplace=True)\n",
    "\n",
    "        wc.drop(labels = wc.iloc[7::8, :].index.to_list(), inplace=True)\n",
    "        wc.reset_index(drop=True,inplace=True)\n",
    "\n",
    "        wc.columns = [\"Date\",\"Weight\"]\n",
    "\n",
    "        wc[\"Weight\"] = wc[\"Weight\"].apply(fix_weight)\n",
    "        wc[\"Weight\"] = wc[\"Weight\"].apply(pd.to_numeric)    \n",
    "        wc[\"Date\"] = wc[\"Date\"].apply(convert_date_format\n",
    "                                     )\n",
    "        BulkCutFill(f)\n",
    "\n",
    "        concat_df = pd.concat([concat_df,wc],ignore_index=True)    \n",
    "        concat_df[\"Weight\"].fillna(method=\"ffill\",inplace=True) \n",
    "\n",
    "        #np.savetxt(\"D:/Laptop Data/Louis Box 2664/Documents/gym data project/cleaned weight log/clean weight log.csv\", \n",
    "         #       concat_df, fmt=\"%s\", header=\"Date,Weight,Goal\", comments=\"\", delimiter=',')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    full_cleaning()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
